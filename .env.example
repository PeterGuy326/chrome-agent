# Chrome Agent Configuration

# Server Configuration
PORT=3000
HOST=localhost
NODE_ENV=development

# Puppeteer Configuration
HEADLESS=true
CHROME_EXECUTABLE_PATH=
USER_DATA_DIR=./data/chrome-user-data

# Storage Configuration
DATA_DIR=./data
LOGS_DIR=./logs
SCREENSHOTS_DIR=./screenshots
EXPORTS_DIR=./exports

# Logging Configuration
LOG_LEVEL=info
ENABLE_SCREENSHOTS=false
ENABLE_DETAILED_LOGS=false

# Security Configuration
API_KEY=your-api-key-here
ENCRYPTION_KEY=your-encryption-key-here

# Rate Limiting
MAX_CONCURRENT_TASKS=3
TASK_TIMEOUT_MS=1800000
STEP_TIMEOUT_MS=30000

# AI/LLM Configuration (for intent parsing and planning)
# NOTE: set AI_PROVIDER=modelscope to use ModelScope's OpenAI-compatible API
AI_PROVIDER=openai # openai | deepseek | custom | modelscope
AI_TEMPERATURE=0.2
AI_MAX_TOKENS=2048
AI_TOP_P=1
AI_SYSTEM_PROMPT=
AI_TIMEOUT=60000

# OpenAI compatible settings
OPENAI_API_KEY=
OPENAI_MODEL=gpt-3.5-turbo
OPENAI_BASE_URL=https://api.openai.com/v1

# DeepSeek settings (OpenAI-compatible API)
DEEPSEEK_API_KEY=
DEEPSEEK_MODEL=deepseek-chat
DEEPSEEK_BASE_URL=https://api.deepseek.com/v1

# ModelScope settings (OpenAI-compatible API)
# When using ModelScope, set AI_PROVIDER=modelscope and fill the values below
MODELSCOPE_API_KEY=
MODELSCOPE_MODEL=
# IMPORTANT: set to your ModelScope OpenAI-compatible base URL
MODELSCOPE_BASE_URL=

# Optional: dedicated models for intent parsing and planning
# If AI_PROVIDER=modelscope and these are empty, defaults will be used:
#   AI_INTENT_MODEL=deepseek-ai/DeepSeek-V2-Lite-Chat
#   AI_PLANNER_MODEL=deepseek-ai/DeepSeek-V3.1
AI_INTENT_MODEL=
AI_PLANNER_MODEL=